{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12cbb82d-b87b-4ede-b907-7f7fcf325961",
   "metadata": {},
   "source": [
    "# The following notebook uses the dataframe on which tracking has been performed and uses the spots coordinates to extract activity from alternate channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb18d9b-2add-413d-be6f-101d3c673e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np \n",
    "import sys \n",
    "import time \n",
    "import zarr\n",
    "import os\n",
    "\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from extract_pixel_data import Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc106e-ee5e-4330-83e4-5c7483e714c4",
   "metadata": {},
   "source": [
    "### Do not change the code in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c5b01d-f937-4cef-b7fc-5f3d1014bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes that your notebook is inside 'Jupyter Notebooks', which is at the same level as 'movie_data'\n",
    "base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'movie_data')\n",
    "\n",
    "zarr_directory = 'zarr_file/all_channels_data'\n",
    "zarr_full_path = os.path.join(base_dir, zarr_directory)\n",
    "\n",
    "input_directory = 'datasets'\n",
    "input_file_name = 'track_df_c3_cleaned.pkl'\n",
    "input_directory_full = os.path.join(base_dir,input_directory, input_file_name)\n",
    "\n",
    "output_directory = 'datasets'\n",
    "output_file_name = 'track_df_cleaned_final_full.pkl'\n",
    "output_directory_full = os.path.join(base_dir,output_directory, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab514a50-a2ea-462b-bc94-cdaad738239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = pd.read_pickle(input_directory_full)\n",
    "# read the zarr file which contains the data of all three channels \n",
    "z = zarr.open(zarr_full_path, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901c771c",
   "metadata": {},
   "source": [
    "### Read the instructions carefully before proceeding with the next steps in the notebook\n",
    "\n",
    "The **main object** to work around with is the **Extractor** object and other methods from it will be used in the next steps. You can always refer to the details of the functions and the class by adding a ? before the object or its methods to access its description. However, below a detailed explanation is provided to run the next steps. \n",
    "\n",
    "Firstly its important to note the channel you have performed detection and tracking on (the channel on which detection and tracking is performed are the same). In the case of the specific example in this notebook detection and tracking were performed on channel 3.\n",
    "\n",
    "**Parameters for setting up the extractor Object**\n",
    "\n",
    "Parameters to change: \n",
    "\n",
    "1. **radii**: This is the list of the variable sigma estimated by gaussian fitting (note: the convention for the list is z,y,x). In the example below its [4,2,2]. You have also provided these estimates in the start in notebook 01 where you have performed the detection. \n",
    "2. **n_jobs**: This parameter allows for parallel processing in certain methods of the class. The default value is -1 which means it will use all available cores - 1. However, you can change it to any number that is below the number of cores in your computer e.g. set it to 3 if you want to use 3 cores. \n",
    "\n",
    "**If you have not changed names of columns for the dataframes in the previous steps you can ignore below**\n",
    "\n",
    "Fixed Parameters (unlikely to be changed): \n",
    "\n",
    "You will not need to change the parameters below until or unless you change the name of columns in the previous notebooks. \n",
    "\n",
    "1. **radi_col_name**: It is a list of the variable sigma estimated by gaussian fitting (note: the convention for the list is z,y,x). This parameter will be fixed for most parts and is important for the function when it extracts pixel information from other channels. \n",
    "2. **frame_col_name**: As the name suggests it takes in the name of the column which stores the frame number \n",
    "\n",
    "\n",
    "**Parameters to change in the extractor.voxel_sum_fixed_background() method**\n",
    "This function calculates a localised voxel sum. This means that it constructs a volume around the spots and a larger volume as background. Then it finds the background locally and subtracts it to get the voxel sum.\n",
    "\n",
    "You will just have to change the channel number anytime this function is called. You will run this function even on the function you have performed detections and tracking on. \n",
    "\n",
    "1. **channel**: The number of channel for which you want to find the voxel sum e.g. if you want to find the voxel sum for channel 3 spots then you will pass 3. \n",
    "\n",
    "\n",
    "mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_variable_bd(center_col_names = col_names, channel = 3)\n",
    "\n",
    "**Parameters to change in the extractor.extract_pixels_data_variable() method**\n",
    "This function calculates multiple values for each spot. It calculates the mean, maximum value, maximum amplitude pixel location etc. \n",
    "\n",
    "1. **channel**: The number of channel for which you want to find the voxel sum e.g. if you want to find the value for channel 3 spots then you will pass 3. \n",
    "\n",
    "\n",
    "You will have to use the following two functions for each channel to get the desired results\n",
    "1. voxel_sum_fixed_background()\n",
    "2. extract_pixels_data_variable()\n",
    "\n",
    "\n",
    "The below function you will run only for the two channels on which detection was not performed previously. Since we will be finding the gaussian estimates and we have already done that for one channel in the start(in our case its channel 3). \n",
    "\n",
    "extractor.run_parallel_frame_processing()\n",
    "\n",
    "**Parameters to change in the extractor.run_parallel_frame_processing()**: \n",
    "1. **expected_sigma**: The expected radius value for a spot in z,y,x axes. This is the same parameter as the simga estimates in notebook 01. \n",
    "2. **center_col_name**: The name of the peak pixel columns in z,y,x. In the case of this notebook and for channel 2 it will be ['c2_peak_z', 'c2_peak_y', 'c2_peak_x']. Note that these column names can be adjusted by you. If you are working with channel 1 then you can name the columns 'c1_peak_z', 'c1_peak_y', 'c1_peak_x'. \n",
    "3. **dist_between_spots**: This is the same as explained in notebook 01. It is the radius in pixels between which two spots cannot exist. If the parameter is 10, it means no two spots can exist between a radius of 5 pixels. \n",
    "4. **channel**: The channel on which to perform the gaussian fitting \n",
    "5. **max_frames**: The number of frames on which you want to perform the gaussian fitting. This is useful for testing however, as a final run you will set all_frames = True and then max_frames will be ignored. \n",
    "6. **all_frames**: If you want to do gaussian fitting on all frames set this to True. If you want to do it to max_frames then set it as false. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b758ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting values of the parameters. Note that if the order of your channels change i.e the channel number changes on \n",
    "# which you performed detection then you might have to change the parameters as explained above. \n",
    "#########################\n",
    "\n",
    "radii_extractor = [4,2,2] #radii for the extractor object \n",
    "n_cores = -1 #n_jobs for extractor class \n",
    "\n",
    "background_radius_for_voxel_sum = [1,1,1] # the background_radius for voxel_sum_fixed_background().\n",
    "                                            # This is the same for channels and can be changed if you think it can yield better results in your case\n",
    "\n",
    "expected_sigma_value = [4,2,2] # for gaussian fitting \n",
    "distance_between_spots = 10 # for gaussian fitting (in terms of pixels)\n",
    "max_frames_to_do_gaussian_fitting = 2 # for gaussian fitting \n",
    "process_all_frames = True #for gaussian fitting \n",
    "\n",
    "########################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb6b1d0-c4eb-4602-bc16-2cf9efd06be9",
   "metadata": {},
   "source": [
    "## In the below cell the Extractor object is created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da560db3-39ca-4f61-95b5-cbd540b92f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Extractor(z, dataframe = track_df, radii=radii_extractor, frame_col_name = 'frame', \n",
    "                      radi_col_name = ['sigma_z', 'sigma_y', 'sigma_x'], n_jobs = n_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dd49ca-8b5b-44a3-9209-78bdc47bae18",
   "metadata": {},
   "source": [
    "# Extract Information for Channel 3 (Clathrin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe465a-d9ad-4d7c-9497-aef4c2e0bcff",
   "metadata": {},
   "source": [
    "## Extracting voxel sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc89b1-e00c-4773-9de6-04a0f3aaedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the channel for which voxel sum is needed and the coordinates around which voxel sum is supposed to be calculated\n",
    "# convention for coords [z,y,x] \n",
    "# convention for channel is 1 for channel 1, 2 for channel 2 and so on \n",
    "# channel number is to passed according to whichever channel we want to extract the data for\n",
    "start_time = time.time()\n",
    "voxel_sum_array_3, _, adj_voxel_sum_3 = extractor.voxel_sum_fixed_background(center_col_names = ['mu_z', 'mu_y', 'mu_x'], channel = 3,\n",
    "                                                                            background_radius=background_radius_for_voxel_sum)\n",
    "end_time = time.time()\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c71025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the channel for which pixel values are needed and the coordinates around which values are supposed to be calculated\n",
    "# convention for coords [z,y,x] \n",
    "# convention for channel is 1 for channel 1, 2 for channel 2 and so on \n",
    "start_time = time.time()\n",
    "offset = [0,0]\n",
    "col_names = ['mu_z', 'mu_y', 'mu_x']\n",
    "# mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_variable_bd(center_col_names = col_names, channel = 3)\n",
    "\n",
    "mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_fixed_bd(center_col_names = col_names, channel = 3)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Adding the extracted data to the dataframe\n",
    "\n",
    "max_loc = np.array(max_loc)\n",
    "track_df['c3_mean_amp'] = mean\n",
    "track_df['c3_voxel_sum'] = voxel_sum_array_3\n",
    "track_df['c3_voxel_sum_adjusted'] = adj_voxel_sum_3 \n",
    "track_df['c3_peak_amp'] = maximum \n",
    "track_df['c3_peak_x'] = max_loc[:,2]\n",
    "track_df['c3_peak_y'] = max_loc[:,1]\n",
    "track_df['c3_peak_z'] = max_loc[:,0]\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62534ae-ab9a-4bb5-9085-2b2da6345c81",
   "metadata": {},
   "source": [
    "# Extract information for Channel 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2655d1b7-0fed-4f65-bd62-cac8f9139910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the channel for which pixel values are needed and the coordinates around which values are supposed to be calculated\n",
    "# convention for coords [z,y,x] \n",
    "# convention for channel is 1 for channel 1, 2 for channel 2 and so on \n",
    "start_time = time.time()\n",
    "offset = [0,0]\n",
    "col_names = ['mu_z', 'mu_y', 'mu_x']\n",
    "# mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_variable_bd(center_col_names = col_names, channel = 2)\n",
    "mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_fixed_bd(center_col_names = col_names, channel = 2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "max_loc = np.array(max_loc)\n",
    "track_df['c2_amp'] = mean\n",
    "track_df['c2_peak'] = maximum\n",
    "track_df['c2_peak_x'] = max_loc[:,2]\n",
    "track_df['c2_peak_y'] = max_loc[:,1]\n",
    "track_df['c2_peak_z'] = max_loc[:,0]\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab68ca-d187-455b-881e-6c4fd8ae772a",
   "metadata": {},
   "source": [
    "## Finding peak pixel for Channel 2 as not sure about the offset between Channel 3 and Channel 2\n",
    "**Reason for offset is being shot from different cameras**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3723171a-af42-4435-b792-4a1d48db6ca9",
   "metadata": {},
   "source": [
    "## Finding mean value around the peak pixel value for channel 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc79466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "col_names = ['c2_peak_z', 'c2_peak_y', 'c2_peak_x']\n",
    "peak_mean,maxima,_,_,_ = extractor.extract_pixels_data_variable_bd(center_col_names = col_names, \n",
    "                                                     channel = 2)\n",
    "end_time = time.time()\n",
    "track_df['c2_peak_mean'] = peak_mean\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4724fe3e-043f-413e-8ef3-9f8fbd27fb06",
   "metadata": {},
   "source": [
    "## Finding voxel sum around peak for channel 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0447c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the channel for which voxel sum is needed and the coordinates around which voxel sum is supposed to be calculated\n",
    "# convention for coords [z,y,x] \n",
    "# convention for channel is 1 for channel 1, 2 for channel 2 and so on \n",
    "start_time = time.time()\n",
    "voxel_sum_array_2, _, adj_voxel_sum_array_2 = extractor.voxel_sum_fixed_background(center_col_names = ['c2_peak_z', 'c2_peak_y', 'c2_peak_x'],\n",
    "                                       channel = 2, background_radius = background_radius_for_voxel_sum)\n",
    "end_time = time.time()\n",
    "\n",
    "#calculated around the peak value coordinates\n",
    "track_df['c2_voxel_sum'] = voxel_sum_array_2\n",
    "track_df['c2_voxel_sum_adjusted'] = adj_voxel_sum_array_2\n",
    "\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c22afa-28b1-45ce-8b2b-8b49eb316152",
   "metadata": {},
   "source": [
    "### Gaussian Fitting for Channel 2 around peak values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9957dd5-d495-4041-94fe-ea299147e6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the gaussian fitting estimates around peak coords for channel 2 \n",
    "#expected sigma value needed for gaussian fitting \n",
    "#set all frames to False for processing limited frames \n",
    "#max_frames determines the frames to be processed if all_frames is false\n",
    "start_time = time.time()\n",
    "channel2_gaussians_df = extractor.run_parallel_frame_processing(expected_sigma = expected_sigma_value, \n",
    "                                        center_col_name = ['c2_peak_z', 'c2_peak_y', 'c2_peak_x'], \n",
    "                                       dist_between_spots = distance_between_spots , channel = 2,  \n",
    "                                       max_frames =  max_frames_to_do_gaussian_fitting, all_frames = process_all_frames)\n",
    "end_time = time.time()\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7650f-f6d3-43d4-969b-4396d3a9c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['c2_gaussian_amp'] = channel2_gaussians_df['amplitude']\n",
    "track_df['c2_mu_x'] = channel2_gaussians_df['mu_x']\n",
    "track_df['c2_mu_y'] = channel2_gaussians_df['mu_y']\n",
    "track_df['c2_mu_z'] = channel2_gaussians_df['mu_z']\n",
    "track_df['c2_sigma_x'] = channel2_gaussians_df['sigma_x']\n",
    "track_df['c2_sigma_y'] = channel2_gaussians_df['sigma_y']\n",
    "track_df['c2_sigma_z'] = channel2_gaussians_df['sigma_z']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2127dc4-fde7-4ff1-b85a-a271d142f5e2",
   "metadata": {},
   "source": [
    "# Extract information for channel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdb118",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = [0,0]\n",
    "col_names = ['mu_z', 'mu_y', 'mu_x']\n",
    "radi_list = ['sigma_z', 'sigma_y', 'sigma_x']\n",
    "# mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_variable_bd(center_col_names = col_names, channel = 1)\n",
    "mean,maximum,minimum,pixel_values,max_loc = extractor.extract_pixels_data_fixed_bd(center_col_names = col_names, channel = 1)\n",
    "\n",
    "max_loc = np.array(max_loc)\n",
    "track_df['c1_amp'] = mean\n",
    "track_df['c1_peak'] = maximum\n",
    "track_df['c1_peak_x'] = max_loc[:,2]\n",
    "track_df['c1_peak_y'] = max_loc[:,1]\n",
    "track_df['c1_peak_z'] = max_loc[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67774a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_sum_array_1, _, adj_voxel_sum_array_1 = extractor.voxel_sum_fixed_background(center_col_names = ['mu_z', 'mu_y', 'mu_x'], channel = 1,\n",
    "                                                                                  background_radius = background_radius_for_voxel_sum)\n",
    "#calculated around the peak value coordinates\n",
    "track_df['c1_voxel_sum'] = voxel_sum_array_1\n",
    "track_df['c1_voxel_sum_adjusted'] = adj_voxel_sum_array_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd66aa1-59b3-4129-8e83-8e6f582549c8",
   "metadata": {},
   "source": [
    "### Perform Guassian Fitting for channel 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24014c-d01a-46ca-b163-9e8d29059916",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "channel1_gaussians_df = extractor.run_parallel_frame_processing(expected_sigma = [4,2,2], \n",
    "                                        center_col_name = ['c1_peak_z', 'c1_peak_y', 'c1_peak_x'], \n",
    "                                       dist_between_spots = 10, channel = 1,  \n",
    "                                       max_frames =  max_frames_to_do_gaussian_fitting, all_frames = process_all_frames)\n",
    "end_time = time.time()\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32a53b-de84-4dba-8f42-96b29295cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df['c1_gaussian_amp'] = channel1_gaussians_df['amplitude']\n",
    "track_df['c1_mu_x'] = channel1_gaussians_df['mu_x']\n",
    "track_df['c1_mu_y'] = channel1_gaussians_df['mu_y']\n",
    "track_df['c1_mu_z'] = channel1_gaussians_df['mu_z']\n",
    "track_df['c1_sigma_x'] = channel1_gaussians_df['sigma_x']\n",
    "track_df['c1_sigma_y'] = channel1_gaussians_df['sigma_y']\n",
    "track_df['c1_sigma_z'] = channel1_gaussians_df['sigma_z']\n",
    "\n",
    "### In the below steps dataframe is being cleaned to make column names consistent for next steps \n",
    "##Renaming columns to maintain data integrity \n",
    "new_col_names = {\n",
    "    'amplitude': 'c3_gaussian_amp', \n",
    "    'mu_x': 'c3_mu_x', \n",
    "    'mu_y': 'c3_mu_y', \n",
    "    'mu_z': 'c3_mu_z', \n",
    "    'sigma_x': 'c3_sigma_x', \n",
    "    'sigma_y': 'c3_sigma_y', \n",
    "    'sigma_z': 'c3_sigma_z', \n",
    "    'c2_peak': 'c2_peak_amp', \n",
    "    'c1_peak': 'c1_peak_amp'\n",
    "}\n",
    "track_df.rename(columns=new_col_names, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4d269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.to_pickle(output_directory_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f33059-0776-41cb-ac91-aa9022cec090",
   "metadata": {},
   "source": [
    "# To test the following functions change the markdown files to code files \n",
    "1. Voxel sum using the variable sigma/radi values directly inferred from the dataset \n",
    "2. Extracting pixel values mean,max etc using fixed radi\n",
    "3. Performing Gaussian Fitting on peak coords for single frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03268c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate distances between the calculated mu values for the channels\n",
    "# distances = np.sqrt(np.sum((track_df[['c1_mu_x', 'c1_mu_y', 'c1_mu_z']].values - track_df[['c2_mu_x', 'c2_mu_y', 'c2_mu_z']].values)**2, axis=1))\n",
    "# track_df['c1_c2_dist'] = distances\n",
    "# distances_ch3_1 = np.sqrt(np.sum((track_df[['c3_mu_x', 'c3_mu_y', 'c3_mu_z']].values - track_df[['c1_mu_x', 'c1_mu_y', 'c1_mu_z']].values)**2, axis=1))\n",
    "# track_df['c3_c1_dist'] = distances_ch3_1\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(distances, bins=100)\n",
    "# plt.xlabel('Distance between mu values of channel 1 and channel 2 (pixels)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.hist(distances_ch3_1, bins=100)\n",
    "# plt.xlabel('Distance between mu values of channel 1 and channel 3 (pixels)')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6ada80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate offset between the calculated mu values for the channels\n",
    "# offsets = track_df[['c3_mu_x', 'c3_mu_y', 'c3_mu_z']].values - track_df[['c2_mu_x', 'c2_mu_y', 'c2_mu_z']].values\n",
    "# track_df['c3_c2_offset_x'] = offsets[:,0]\n",
    "# track_df['c3_c2_offset_y'] = offsets[:,1]\n",
    "# track_df['c3_c2_offset_z'] = offsets[:,2]\n",
    "\n",
    "# offsets = track_df[['c3_mu_x', 'c3_mu_y', 'c3_mu_z']].values - track_df[['c1_mu_x', 'c1_mu_y', 'c1_mu_z']].values\n",
    "# track_df['c3_c1_offset_x'] = offsets[:,0]\n",
    "# track_df['c3_c1_offset_y'] = offsets[:,1]\n",
    "# track_df['c3_c1_offset_z'] = offsets[:,2]\n",
    "\n",
    "# plt.plot(track_df['c3_c2_offset_x'], track_df['c3_c2_offset_y'], 'o')\n",
    "# plt.xlabel('Offset in x (pixels)')\n",
    "# plt.ylabel('Offset in y (pixels)')\n",
    "# plt.title('Offset between mu values of channel 3 and channel 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb277333",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(track_df['c3_c2_offset_x'],50)\n",
    "plt.hist(track_df['c3_c2_offset_y'],50)\n",
    "plt.hist(track_df['c3_c2_offset_z'],50)\n",
    "plt.xlabel('Offset (pixels)')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report mean and std value of offset xyz\n",
    "print('Mean offset x:', np.mean(track_df['c3_c2_offset_x']))\n",
    "print('Mean offset y:', np.mean(track_df['c3_c2_offset_y']))\n",
    "print('Mean offset z:', np.mean(track_df['c3_c2_offset_z']))\n",
    "print('Std offset x:', np.std(track_df['c3_c2_offset_x']))\n",
    "print('Std offset y:', np.std(track_df['c3_c2_offset_y']))\n",
    "print('Std offset z:', np.std(track_df['c3_c2_offset_z']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad7292-f6d1-4a91-885e-e65038964e66",
   "metadata": {},
   "source": [
    "### Function 1 (Voxel Sum)\n",
    "start_time = time.time()\n",
    "voxel_sum_array_variable, _ = extractor.voxel_sum_variable_bd(center_col_names = ['mu_z', 'mu_y', 'mu_x'], channel = 3)\n",
    "end_time = time.time()\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c452565a-79ae-4b62-a6ad-6324b7cec349",
   "metadata": {},
   "source": [
    "### Function 2 (Extracting Pixel Values)\n",
    "start_time = time.time()\n",
    "offset = [0,0]\n",
    "col_names = ['mu_z', 'mu_y', 'mu_x']\n",
    "radii = [4, 2, 2]\n",
    "mean_v,maximum_v,minimum_v,pixel_values_v,max_loc_v = extractor.extract_pixels_data_fixed_bd(center_col_names = col_names, channel = 3)\n",
    "\n",
    "end_time = time.time()\n",
    "print('time taken (seconds)', end_time - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b895a6-fad1-4319-b378-a3dc5568b052",
   "metadata": {},
   "source": [
    "### Function 3 (Gaussian fitting on one frame for one channel)\n",
    "df = extractor.gaussian_fitting_single_frame(expected_sigma = [4,2,2], \n",
    "                              center_col_names = ['c2_peak_z', 'c2_peak_y', 'c2_peak_x'],\n",
    "                                      frame = 0, channel = 2, dist_between_spots = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
