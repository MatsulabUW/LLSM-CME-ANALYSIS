{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7699bd06-dc64-4aee-8802-d99882165dd1",
   "metadata": {},
   "source": [
    "# This is the first step in the pipeline\n",
    "### Spots are detected in this notebook. The input file is expected to be in the zarr format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a4feae-de71-474c-a3b1-9d442d2a2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import zarr\n",
    "import napari \n",
    "import dask.array as da \n",
    "\n",
    "pythonPackagePath = os.path.abspath('../src/')\n",
    "sys.path.append(pythonPackagePath)\n",
    "from parallel import Detector\n",
    "from gaussian_visualization import visualize_3D_gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebdcb7e-0da4-4aee-a372-e2128ce2cfae",
   "metadata": {},
   "source": [
    "### Do not change the code in cell below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690e846-bfa8-46ae-947f-64b537f09bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes that your notebook is inside 'Jupyter Notebooks', which is at the same level as 'test_data'\n",
    "base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'movie_data')\n",
    "# base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'test_movie_1')\n",
    "\n",
    "zarr_directory = 'zarr_file/all_channels_data'\n",
    "zarr_full_path = os.path.join(base_dir, zarr_directory)\n",
    "\n",
    "save_directory = 'datasets'\n",
    "save_directory_full = os.path.join(base_dir, save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa8f87",
   "metadata": {},
   "source": [
    "## Follow the Instructions below to run through the notebook properly \n",
    "\n",
    "This notebook detects spots on your movie. The movie should be a zarr object; if it's not, run Final/Data Preparation/full_movie_to_zarr.ipynb\n",
    "\n",
    "**Parameters to adjust below** \n",
    "\n",
    "* **channel_to_detect**: Which channel will be tracked? This should be the channel with the longest tracks (i.e. AP2). Options are channel 1, 2, or 3.\n",
    "\n",
    "* **threshold_intensity**: What intensity value distinguishes background from signal? Open up a frame of the movie in Fiji or napari (at the end of this notebook) and mouse over different pixels to figure out this threshold value.\n",
    "\n",
    "* **all_frames**: When initially optimizing, set this to false and set number_frames_to_detect to 2, in order to run detection on only two time points. This will speed up diagnosing detection quality at the end of the notebook.\n",
    "\n",
    "Additional parameters for optimization:\n",
    "\n",
    "* **dist_between_spots**: this distance divided by 2 is the minimum distance that should exist between spots in pixels. For example if you set this to 10 then all spots within 5 pixels of the center of your spot will not be detected. \n",
    "* **sigma_estimations**: The expected radius of our spots, in pixels, as [spread_in_z, spread_in_y, spread_in_x]. You can measure the width of a spot in Fiji and divide by two.\n",
    "* **n_jobs**: The number of CPUs to use for detections. You can set it to -1 and it will use all of your machine's CPUs but one for processing. \n",
    "\n",
    "* **number_frames_to_detect**: the number of frames to process. This can be useful when you just want to test your parameters selected for the Detector object like spot_intensity, dist_between_spots and sigma_estimates. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec841e",
   "metadata": {},
   "source": [
    "## Set all parameters in the below cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refer to the above cell for explanation of each parameter \n",
    "channel_to_detect = 3 \n",
    "threshold_intensity = 180\n",
    "all_frames = True\n",
    "\n",
    "dist_between_spots = 10\n",
    "sigma_estimations = [4,2,2]\n",
    "n_jobs = -1\n",
    "number_frames_to_detect = 130     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8dc259-df31-401a-abd5-20a1e9c4e9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the zarr file by adding file path in read mode\n",
    "z2 = zarr.open(zarr_full_path, mode='r')\n",
    "frames = z2.shape[0]\n",
    "print(f'the number of frames are {frames}')\n",
    "z2.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9983d-8633-46d7-a59a-7885c93fbd1b",
   "metadata": {},
   "source": [
    "## In the below cell Detector object is initilized to perform detection. More details on the Detector object can be attained by the following line of code: \n",
    "**copy and paste in a new cell**\n",
    "\n",
    "?Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a03bc8-4326-4fb0-87c0-d3af7eb67e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(zarr_obj = z2, \n",
    "                    save_directory = save_directory_full, \n",
    "                    spot_intensity = threshold_intensity, \n",
    "                    dist_between_spots = dist_between_spots, \n",
    "                    sigma_estimations = sigma_estimations, n_jobs = n_jobs, channel_to_detect = channel_to_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9763ea65-4a6c-4061-8e42-29e84012bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following function returns the dataframe and also saves it to the provided path in pkl format\n",
    "#set all_frames = True, to process all the time frames \n",
    "#max_frames is useful when you just want to perform detection on a subset of frames. \n",
    "#Note: when all_frames= True then max_frames is ignored \n",
    "df = detector.run_parallel_frame_processing(max_frames = number_frames_to_detect, all_frames = all_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb5443-0c8f-41f3-9464-ba14e2bbf75c",
   "metadata": {},
   "source": [
    "# Visualising the Output\n",
    "## Labels are only for time frame 0, for all z slices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df6b924",
   "metadata": {},
   "source": [
    "## Below you can see detected spots as masks on the original image and can adjust detection parameters if you think spots are not detected correctly \n",
    "\n",
    "### Once you are in the napari viewer you should adjust the contrast and the opacity to make sure both the masks and the raw movie is visible properly.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a mask of the detections\n",
    "masks = visualize_3D_gaussians(zarr_obj = z2, gaussians_df = df)\n",
    "\n",
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#access channel 3 only from zarr array \n",
    "dask_array = da.from_zarr(z2)\n",
    "\n",
    "#the axis arrangement is (t,c,z,y,x)\n",
    "# importing the channel_to_detect\n",
    "detection_channel = dask_array[:,:,:,:,:]\n",
    "\n",
    "# which channel to show\n",
    "visibility_mask = [False, False, False]\n",
    "visibility_mask[channel_to_detect-1] = True\n",
    "\n",
    "# Add the 4D stack to the viewer\n",
    "# Can change the names of the channels as needed\n",
    "layer_raw = viewer.add_image(detection_channel, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'], interpolation3d = 'nearest', blending = 'additive', colormap = 'magenta', visible = visibility_mask)\n",
    "# layer_raw = viewer.add_image(detection_channel, channel_axis = 1, name = ['detection channel'], interpolation3d = 'nearest', blending = 'additive', colormap = 'magenta')\n",
    "\n",
    "# layer_mask = viewer.add_image(masks, name = 'detections mask')\n",
    "layer_mask = viewer.add_image(masks, name = 'detections', interpolation3d = 'nearest', blending = 'additive', colormap = 'green')\n",
    "\n",
    "#other useful parameters \n",
    "#color_map = list\n",
    "#contrast_limits = list of list \n",
    "\n",
    "# Add Bounding Box\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0113030",
   "metadata": {},
   "source": [
    "If the detections don't line up well with the spots in the image:\n",
    "* make sure you are looking at the first time point\n",
    "* mouse over the spots in napari to get a sense for the intensity of the spots vs background - use the threshold distinguishing spots from background as threshold_intensity \n",
    "* vary the dist_between_spots: if the detections are at a higher density than the visible spots, increase the dist_between_spots. And vice versa, if you see spots at a higher density than detections, lower the dist_between_spots.\n",
    "* If the detections are missing larger or smaller spots you can try increasing or decreasing the sigma_estimations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c08adc4",
   "metadata": {},
   "source": [
    "# move to 02.filtering_spots for next steps "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
