{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c7afc9",
   "metadata": {},
   "source": [
    "# Main Focus of the Notebook: Running Laptrack on detections\n",
    "\n",
    "### This notebook takes as input the dataframe which contains filtered detected spots and runs laptrack module on it. \n",
    "### A new dataframe containing tree id and track id is returned. For us main variable for tracks is track id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a96b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from laptrack import LapTrack, ParallelBackend\n",
    "import napari\n",
    "from skimage import io\n",
    "import time  \n",
    "import os \n",
    "import sys\n",
    "import zarr \n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d2870",
   "metadata": {},
   "source": [
    "### Do not change the code in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b24b38-fc1d-4728-9e74-5659903ec615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes that your notebook is inside 'Jupyter Notebooks', which is at the same level as 'test_data'\n",
    "base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'test_movie_1')\n",
    "\n",
    "zarr_directory = 'zarr_file/all_channels_data'\n",
    "zarr_full_path = os.path.join(base_dir, zarr_directory)\n",
    "\n",
    "input_directory = 'datasets'\n",
    "input_file_name = 'cleaned_spots_intensities_c3_all.pkl'\n",
    "input_directory_full = os.path.join(base_dir,input_directory, input_file_name)\n",
    "\n",
    "output_directory = 'datasets'\n",
    "output_file_name = 'track_df_c3_cleaned.pkl'\n",
    "output_directory_full = os.path.join(base_dir,output_directory, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a796435",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_spots_df = pd.read_pickle(input_directory_full)\n",
    "z2 = zarr.open(zarr_full_path, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8e470",
   "metadata": {},
   "source": [
    "## Parameter to optimize \n",
    "\n",
    "1. **max_distance:** The cost cutoff for the connected points in the track."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a146a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 2.5\n",
    "lt = LapTrack(\n",
    "    track_dist_metric=\"sqeuclidean\",  # The similarity metric for particles. See `scipy.spatial.distance.cdist` for allowed values.\n",
    "    # the square of the cutoff distance for the \"sqeuclidean\" metric\n",
    "    track_cost_cutoff=max_distance**2,\n",
    "    gap_closing_cost_cutoff = (2*max_distance)**2,\n",
    "    gap_closing_max_frame_count = 1,\n",
    "    splitting_dist_metric=\"sqeuclidean\",\n",
    "    splitting_cost_cutoff=False,  # Enable splitting with a cost cutoff\n",
    "    merging_dist_metric=\"sqeuclidean\",\n",
    "    merging_cost_cutoff=False  # Enable merging with a cost cutoff\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8cce581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 18.923552751541138 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "track_df, split_df, merge_df = lt.predict_dataframe(\n",
    "    cleaned_spots_df,\n",
    "    coordinate_cols=[\n",
    "        \"mu_x\",\n",
    "        \"mu_y\",\n",
    "        \"mu_z\"\n",
    "    ],  # the column names for the coordinates\n",
    "    frame_col=\"frame\",  # the column name for the frame (default \"frame\")\n",
    "    only_coordinate_cols=False,  # if False, returned track_df includes columns not in coordinate_cols.\n",
    "    # False will be the default in the major release.\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total execution time: {execution_time} seconds\")\n",
    "track_df = track_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "356fb81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report number of frames and a random color per track\n",
    "\n",
    "import random\n",
    "\n",
    "# Calculate the number of unique frames for each track and create a mapping from track_id to number_of_frames\n",
    "frame_counts = track_df.groupby('track_id')['frame'].nunique().to_dict()\n",
    "\n",
    "# Map the frame counts to the original dataframe, creating a new column\n",
    "track_df['number_of_frames'] = track_df['track_id'].map(frame_counts)\n",
    "\n",
    "# Assuming 'track_df' is your DataFrame\n",
    "track_ids = track_df['track_id'].unique().tolist()\n",
    "\n",
    "# Generate a list of random colors\n",
    "colors = [random.randint(0, 255) for _ in range(len(track_ids))]\n",
    "\n",
    "# Create a dictionary that maps each track id to a random color\n",
    "color_dict = dict(zip(track_ids, colors))\n",
    "\n",
    "# Now you can use this dictionary to assign colors to the tracks\n",
    "track_df['color'] = track_df['track_id'].map(color_dict)\n",
    "# track_df['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6207c5",
   "metadata": {},
   "source": [
    "### You can visualise the performance of the tracking algorithm in napari. If you feel adjustment is needed for the tracking parameters, you can adjust the parameters mentioned in the start accordingly. \n",
    "\n",
    "Once you open napari adjust the contrast so that spots are clearly visible \n",
    "\n",
    "Possible Adjustment Examples\n",
    "\n",
    "1. If a single track appears to be broken into multiple tracks you can increase the max_distance and rerun tracking \n",
    "2. If multiple tracks appear to be merged into a single track you can decrease the max_distance and rerun tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2437cd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makamats/opt/anaconda3/envs/cme_pipeline/lib/python3.10/site-packages/napari/layers/tracks/tracks.py:620: UserWarning: Previous color_by key 'track_id_rand' not present in features. Falling back to track_id\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#access channel 3 only from zarr array \n",
    "dask_array = da.from_zarr(z2)\n",
    "\n",
    "#the axis arrangement is (t,c,z,y,x)\n",
    "#for the sake of improved performance only 1 channel could be imported here (if images get super large and performance issues occur)\n",
    "all_channels = dask_array[:,:,:,:,:]\n",
    "\n",
    "# Add the 4D stack to the viewer\n",
    "# layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'])\n",
    "layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'], contrast_limits=[110,250], interpolation3d = 'nearest', blending = 'additive', colormap = 'gray_r', visible = [False, False, True])\n",
    "\n",
    "# # randomize the track ids and save the track ids in a list\n",
    "# track_ids_shuffle = track_df['track_id'].tolist()\n",
    "# random.shuffle(track_ids_shuffle)\n",
    "\n",
    "properties = dict({\n",
    "    # 'number_of_frames': dict(zip(track_df.index.tolist(), track_df['number_of_frames']))\n",
    "    'track_id_rand': track_df['color'],\n",
    "    'number_of_frames': track_df['number_of_frames']\n",
    "    \n",
    "})\n",
    "# add detections here!\n",
    "# also rejected ones \n",
    "\n",
    "tracks_layer = viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties, color_by='track_id_rand', colormap = 'hsv', name = 'tracks')\n",
    "# tracks_layer2 = viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties, color_by='number_of_frames', colormap = 'inferno', name = 'tracks by frame count')\n",
    "\n",
    "points_layer = viewer.add_points(cleaned_spots_df[[\"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], size=2, \n",
    "                                properties=properties, name = 'Cleaned Spots', face_color = 'white', symbol = 'ring')\n",
    "\n",
    "#  Add Bounding Box\n",
    "\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n",
    "\n",
    "# Now, the dataframe 'data_with_frame_counts' contains an additional column 'number_of_frames'\n",
    "# which indicates how many unique frames each track appears in.\n",
    "# data_with_frame_counts['number_of_frames'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b0914",
   "metadata": {},
   "source": [
    "# View a subset range of slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c82765",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# min and max z to show\n",
    "min_z = 10\n",
    "max_z = 20\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# for a limited number of z slices\n",
    "image_slice = all_channels[:,:,min_z:max_z,:,:]\n",
    "\n",
    "# for a limited number of z slices\n",
    "tracks_slice = track_df[(track_df['mu_z'] > min_z) & (track_df['mu_z'] < max_z)]\n",
    "tracks_slice \n",
    "\n",
    "properties_slice = dict({\n",
    "    # 'number_of_frames': dict(zip(track_df.index.tolist(), track_df['number_of_frames']))\n",
    "    'track_id_rand': tracks_slice['color'],\n",
    "    'number_of_frames': tracks_slice['number_of_frames']\n",
    "})\n",
    "\n",
    "points_slice= cleaned_spots_df[(cleaned_spots_df['mu_z'] > min_z) & (cleaned_spots_df['mu_z'] < max_z)]\n",
    "\n",
    "layer_raw = viewer.add_image(image_slice, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'],contrast_limits=[110,250], translate = [0,min_z,0,0], interpolation3d = 'nearest', blending = 'additive', colormap = 'gray_r', visible = [False, False, True])\n",
    "tracks_layer = viewer.add_tracks(tracks_slice[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties_slice, color_by='track_id_rand', colormap = 'hsv', name = 'tracks')\n",
    "points_layer = viewer.add_points(points_slice[[\"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], size=2, \n",
    "                                properties=properties_slice, name = 'Cleaned Spots', face_color = 'white', symbol = 'ring')\n",
    "\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a028f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#access channel 3 only from zarr array \n",
    "dask_array = da.from_zarr(z2)\n",
    "\n",
    "#the axis arrangement is (t,c,z,y,x)\n",
    "#for the sake of improved performance only 1 channel could be imported here (if images get super large and performance issues occur)\n",
    "all_channels = dask_array[:,:,:,4:2050,:]\n",
    "\n",
    "# Add the 4D stack to the viewer\n",
    "# layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'])\n",
    "layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'], interpolation3d = 'nearest', blending = 'additive', colormap = 'gray_r', visible = [False, False, True])\n",
    "\n",
    "viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], name = 'all tracks')\n",
    "# color by track id or track length\n",
    "\n",
    "#other useful parameters \n",
    "#color_map = list\n",
    "#contrast_limits = list of list \n",
    "\n",
    "# Add Bounding Box\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2b495",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makamats/opt/anaconda3/envs/cme_pipeline/lib/python3.10/site-packages/napari/layers/tracks/tracks.py:620: UserWarning: Previous color_by key 'track_id_rand' not present in features. Falling back to track_id\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#access channel 3 only from zarr array \n",
    "dask_array = da.from_zarr(z2)\n",
    "\n",
    "#the axis arrangement is (t,c,z,y,x)\n",
    "#for the sake of improved performance only 1 channel could be imported here (if images get super large and performance issues occur)\n",
    "all_channels = dask_array[:,:,:,:,:]\n",
    "\n",
    "# Add the 4D stack to the viewer\n",
    "# layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'])\n",
    "layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'], interpolation3d = 'nearest', blending = 'additive', colormap = 'gray_r', visible = [False, False, True])\n",
    "\n",
    "# # randomize the track ids and save the track ids in a list\n",
    "# track_ids_shuffle = track_df['track_id'].tolist()\n",
    "# random.shuffle(track_ids_shuffle)\n",
    "\n",
    "properties = dict({\n",
    "    # 'number_of_frames': dict(zip(track_df.index.tolist(), track_df['number_of_frames']))\n",
    "    'track_id_rand': track_df['color'],\n",
    "    'number_of_frames': track_df['number_of_frames']\n",
    "    \n",
    "})\n",
    "# add detections here!\n",
    "# also rejected ones \n",
    "\n",
    "tracks_layer = viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties, color_by='track_id_rand', colormap = 'hsv', name = 'tracks')\n",
    "# tracks_layer2 = viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties, color_by='number_of_frames', colormap = 'inferno', name = 'tracks by frame count')\n",
    "\n",
    "points_layer = viewer.add_points(cleaned_spots_df[[\"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], size=2, \n",
    "                                properties=properties, name = 'Cleaned Spots', face_color = 'white', symbol = 'ring')\n",
    "\n",
    "#  Add Bounding Box\n",
    "\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n",
    "\n",
    "# Now, the dataframe 'data_with_frame_counts' contains an additional column 'number_of_frames'\n",
    "# which indicates how many unique frames each track appears in.\n",
    "# data_with_frame_counts['number_of_frames'].hist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
