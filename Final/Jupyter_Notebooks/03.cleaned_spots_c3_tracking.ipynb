{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c7afc9",
   "metadata": {},
   "source": [
    "# Main Focus of the Notebook: Running Laptrack on detections\n",
    "\n",
    "### This notebook takes as input the dataframe which contains filtered detected spots and runs laptrack module on it. \n",
    "### A new dataframe containing tree id and track id is returned. For us main variable for tracks is track id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a96b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from laptrack import LapTrack, ParallelBackend\n",
    "import napari\n",
    "from skimage import io\n",
    "import time  \n",
    "import os \n",
    "import sys\n",
    "import zarr \n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d2870",
   "metadata": {},
   "source": [
    "### Do not change the code in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57b24b38-fc1d-4728-9e74-5659903ec615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This assumes that your notebook is inside 'Jupyter Notebooks', which is at the same level as 'test_data'\n",
    "base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'movie_data')\n",
    "# base_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..', 'test_movie_1')\n",
    "\n",
    "\n",
    "zarr_directory = 'zarr_file/all_channels_data'\n",
    "zarr_full_path = os.path.join(base_dir, zarr_directory)\n",
    "\n",
    "input_directory = 'datasets'\n",
    "input_file_name = 'cleaned_spots_intensities_c3_all.pkl'\n",
    "input_directory_full = os.path.join(base_dir,input_directory, input_file_name)\n",
    "\n",
    "output_directory = 'datasets'\n",
    "output_file_name = 'track_df_c3_cleaned.pkl'\n",
    "output_directory_full = os.path.join(base_dir,output_directory, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a796435",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_spots_df = pd.read_pickle(input_directory_full)\n",
    "z2 = zarr.open(zarr_full_path, mode='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe8e470",
   "metadata": {},
   "source": [
    "## Parameters to optimize \n",
    "\n",
    "* **max_distance:** The distance cost cutoff for the connected points in the track.\n",
    "* **gap_size:** The number of consecutive detection gaps allowed \n",
    "* **gap_closing_cost_tolerance:** How permissive gap closing is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a146a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance = 2.5 # in pixels\n",
    "gap_size = 1 # in frames\n",
    "gap_closing_cost_tolerance = 1 # default: 1\n",
    "\n",
    "lt = LapTrack(\n",
    "    track_dist_metric=\"sqeuclidean\",  # The similarity metric for particles. See `scipy.spatial.distance.cdist` for allowed values.\n",
    "    # the square of the cutoff distance for the \"sqeuclidean\" metric\n",
    "    track_cost_cutoff=max_distance**2,\n",
    "    gap_closing_cost_cutoff = (gap_closing_cost_tolerance*2*max_distance)**2,\n",
    "    # gap_closing_cost_cutoff = (2.5*max_distance)**2,\n",
    "\n",
    "    gap_closing_max_frame_count = gap_size,\n",
    "    splitting_dist_metric=\"sqeuclidean\",\n",
    "    splitting_cost_cutoff=False,  # Enable splitting with a cost cutoff\n",
    "    merging_dist_metric=\"sqeuclidean\",\n",
    "    merging_cost_cutoff=False  # Enable merging with a cost cutoff\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8cce581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 32.659488916397095 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "track_df, split_df, merge_df = lt.predict_dataframe(\n",
    "    cleaned_spots_df,\n",
    "    coordinate_cols=[\n",
    "        \"mu_x\",\n",
    "        \"mu_y\",\n",
    "        \"mu_z\"\n",
    "    ],  # the column names for the coordinates\n",
    "    frame_col=\"frame\",  # the column name for the frame (default \"frame\")\n",
    "    only_coordinate_cols=False,  # if False, returned track_df includes columns not in coordinate_cols.\n",
    "    # False will be the default in the major release.\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total execution time: {execution_time} seconds\")\n",
    "track_df = track_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "356fb81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report number of frames and a random color per track\n",
    "\n",
    "import random\n",
    "\n",
    "# Calculate the number of unique frames for each track and create a mapping from track_id to number_of_frames\n",
    "frame_counts = track_df.groupby('track_id')['frame'].nunique().to_dict()\n",
    "\n",
    "# Map the frame counts to the original dataframe, creating a new column\n",
    "track_df['number_of_frames'] = track_df['track_id'].map(frame_counts)\n",
    "\n",
    "# Assuming 'track_df' is your DataFrame\n",
    "track_ids = track_df['track_id'].unique().tolist()\n",
    "\n",
    "# Generate a list of random colors\n",
    "colors = [random.randint(0, 255) for _ in range(len(track_ids))]\n",
    "\n",
    "# Create a dictionary that maps each track id to a random color\n",
    "color_dict = dict(zip(track_ids, colors))\n",
    "\n",
    "# Now you can use this dictionary to assign colors to the tracks\n",
    "track_df['color'] = track_df['track_id'].map(color_dict)\n",
    "# track_df['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6207c5",
   "metadata": {},
   "source": [
    "### Visualise the performance of the tracking algorithm in napari. If there is a mismatch between the tracks and your visual tracking of the spots, you can adjust the parameters at the top of this notebook (see below). \n",
    "\n",
    "Once you open napari adjust the contrast so that spots are clearly visible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2437cd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makamats/opt/anaconda3/envs/cme_pipeline/lib/python3.10/site-packages/napari/layers/tracks/tracks.py:620: UserWarning: Previous color_by key 'track_id_rand' not present in features. Falling back to track_id\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a napari viewer\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "#access channel 3 only from zarr array \n",
    "dask_array = da.from_zarr(z2)\n",
    "\n",
    "#the axis arrangement is (t,c,z,y,x)\n",
    "#for the sake of improved performance only 1 channel could be imported here (if images get super large and performance issues occur)\n",
    "all_channels = dask_array[:,:,:,:,:]\n",
    "\n",
    "# Add the 4D stack to the viewer\n",
    "# layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'])\n",
    "layer_raw = viewer.add_image(all_channels, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'], contrast_limits=[110,250], interpolation3d = 'nearest', blending = 'additive', colormap = 'gray_r', visible = [False, False, True])\n",
    "\n",
    "# # randomize the track ids and save the track ids in a list\n",
    "# track_ids_shuffle = track_df['track_id'].tolist()\n",
    "# random.shuffle(track_ids_shuffle)\n",
    "\n",
    "properties = dict({\n",
    "    # 'number_of_frames': dict(zip(track_df.index.tolist(), track_df['number_of_frames']))\n",
    "    'track_id_rand': track_df['color'],\n",
    "    'number_of_frames': track_df['number_of_frames']\n",
    "    \n",
    "})\n",
    "# add detections here!\n",
    "# also rejected ones \n",
    "\n",
    "tracks_layer = viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties, color_by='track_id_rand', tail_length = 15, tail_width = 6, colormap = 'hsv', name = 'tracks')\n",
    "# tracks_layer2 = viewer.add_tracks(track_df[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties, color_by='number_of_frames', colormap = 'inferno', name = 'tracks by frame count')\n",
    "\n",
    "points_layer = viewer.add_points(cleaned_spots_df[[\"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], size=2, \n",
    "                                properties=properties, name = 'Cleaned Spots', face_color = 'white', symbol = 'ring')\n",
    "\n",
    "#  Add Bounding Box\n",
    "\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n",
    "\n",
    "# Now, the dataframe 'data_with_frame_counts' contains an additional column 'number_of_frames'\n",
    "# which indicates how many unique frames each track appears in.\n",
    "# data_with_frame_counts['number_of_frames'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b0914",
   "metadata": {},
   "source": [
    "# View a subset range of slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15c82765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/makamats/opt/anaconda3/envs/cme_pipeline/lib/python3.10/site-packages/napari/layers/tracks/tracks.py:620: UserWarning: Previous color_by key 'track_id_rand' not present in features. Falling back to track_id\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# min and max z to show\n",
    "min_z = 15\n",
    "max_z = 36\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# for a limited number of z slices\n",
    "image_slice = all_channels[:,:,min_z:max_z,:,:]\n",
    "\n",
    "# for a limited number of z slices\n",
    "tracks_slice = track_df[(track_df['mu_z'] > min_z) & (track_df['mu_z'] < max_z)]\n",
    "tracks_slice \n",
    "\n",
    "properties_slice = dict({\n",
    "    # 'number_of_frames': dict(zip(track_df.index.tolist(), track_df['number_of_frames']))\n",
    "    'track_id_rand': tracks_slice['color'],\n",
    "    'number_of_frames': tracks_slice['number_of_frames']\n",
    "})\n",
    "\n",
    "points_slice= cleaned_spots_df[(cleaned_spots_df['mu_z'] > min_z) & (cleaned_spots_df['mu_z'] < max_z)]\n",
    "\n",
    "layer_raw = viewer.add_image(image_slice, channel_axis = 1, name = ['channel 1', 'channel 2', 'channel 3'],contrast_limits=[110,250], translate = [0,min_z,0,0], interpolation3d = 'nearest', blending = 'additive', colormap = 'gray_r', visible = [False, False, True])\n",
    "tracks_layer = viewer.add_tracks(tracks_slice[[\"track_id\", \"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], properties=properties_slice, color_by='track_id_rand', tail_length = 15, tail_width = 6, colormap = 'hsv', name = 'tracks')\n",
    "points_layer = viewer.add_points(points_slice[[\"frame\", \"mu_z\", \"mu_y\", \"mu_x\"]], size=2, \n",
    "                                properties=properties_slice, name = 'Cleaned Spots', face_color = 'white', symbol = 'ring')\n",
    "\n",
    "layer_raw[0].bounding_box.visible = True\n",
    "layer_raw[1].bounding_box.visible = True\n",
    "layer_raw[2].bounding_box.visible = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a028f111",
   "metadata": {},
   "source": [
    "## Based on your visual inspection of the tracks, adjust the tracking parameters:\n",
    "\n",
    "* If a single track appears to be broken into multiple tracks you can increase the max_distance and/or increase the gap size and rerun tracking \n",
    "\n",
    "* If multiple tracks appear to be merged into a single track you can decrease the max_distance and/or decrease the gap size and rerun tracking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4b8e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a pickle file\n",
    "track_df.to_pickle(output_directory_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923cfaaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
